<p align="center">
  <h1 align="center">Inpaint4DNeRF: Promptable Spatio-Temporal NeRF Inpainting with Generative Diffusion Models</h1>
  <p align="center">
    <a href="https://openreview.net/profile?id=~Han_Jiang4"><strong>Han Jiang<sup>*</sup></strong></a>
    &nbsp;&nbsp;
    <a href="https://openreview.net/profile?id=~Haosen_Sun3"><strong>Haosen Sun<sup>*</sup></strong></a>
    &nbsp;&nbsp;
    <a href="https://openreview.net/profile?id=~Ruoxuan_LI1"><strong>Ruoxuan LI<sup>*</sup></strong></a>
    &nbsp;&nbsp;
    <a href="https://yuwingtai.github.io/"><strong>Yu-Wing Tai</strong></a>
    &nbsp;&nbsp;
    <a href="http://www.cs.ust.hk/~cktang/"><strong>Chi-Keung Tang</strong></a>
    &nbsp;&nbsp;
    <strong>(*Equal contribution)</strong></a>
  </p>
  <br>
</p>
[**Project**](https://hjiangav.github.io/inpaint4dnerf//) | [**Paper**](https://arxiv.org/abs/2401.00208)

---

## Updates

## Introduction
Our generative Inpaint4DNeRF proposes a text-guided approach for inpainting the relevant background after removing static foreground objects specified by a user-supplied prompt, where multiview consistency is meticulously maintained. Our generative Inpaint4DNeRF baseline framework is general which can be readily extended to dynamic NeRFs, where temporal consistency can be naturally handled in a similar way as our multiview consistency. The code will release soon.

## Baseline Overview
![avatar](Baseline.png)

## BibTeX
<pre>
@misc{inpaint4dnerf,
      title={Inpaint4DNeRF: Promptable Spatio-Temporal NeRF Inpainting with Generative Diffusion Models}, 
      author={Han Jiang and Haosen Sun and Ruoxuan Li and Chi-Keung Tang and Yu-Wing Tai},
      year={2023},
      eprint={2401.00208},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
</pre>
